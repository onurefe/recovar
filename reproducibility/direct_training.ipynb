{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cfd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:34:41.910230: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-04 17:34:41.928617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-04 17:34:41.928636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-04 17:34:41.928648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-04 17:34:41.932231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from direct_trainer import DirectTrainer\n",
    "from recovar import RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder\n",
    "from config import (STEAD_TIME_WINDOW, INSTANCE_TIME_WINDOW, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feaf54af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:34:53.920197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.943062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.943195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22141 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'stead'\n",
    "MODEL = RepresentationLearningMultipleAutoencoder()\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/ege/recovar_data_preprocessed/stead_pseudorandom_state_ne_subsampled/SUBSAMPLED_100_NOISE_40.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa67e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b19bb",
   "metadata": {},
   "source": [
    "### Option 1. Preprocess the whole data, load it into memory and separate train/val files from there on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.create_subsampled_datasets(\n",
    " #   dataset='stead',\n",
    "  #  output_dir=PREPROCESSED_DATASET_DIRECTORY,\n",
    "   # noise_percentages=[0, 10, 20, 90, 100],\n",
    "    #subsampling_factor=1.0, \n",
    "    #maintain_constant_size=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6092e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 176448 samples (EQ: 105879, NO: 70569)\n",
      "Val: 58816 samples (EQ: 35293, NO: 23523)\n",
      "\n",
      "Starting training...\n",
      "Train samples: 176448\n",
      "Val samples: 58816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:25.498332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:45.324651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f0f3790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-04 17:09:45.324669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2025-07-04 17:09:45.332786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-04 17:09:45.404756: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - ETA: 0s - loss: 1.6378\n",
      "Epoch 1: val_loss improved from inf to 1.45220, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 119s 139ms/step - loss: 1.6378 - val_loss: 1.4522 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.3034\n",
      "Epoch 2: val_loss improved from 1.45220 to 1.25263, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.3034 - val_loss: 1.2526 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.1491\n",
      "Epoch 3: val_loss improved from 1.25263 to 1.22802, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.1491 - val_loss: 1.2280 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0843\n",
      "Epoch 4: val_loss improved from 1.22802 to 1.08144, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0843 - val_loss: 1.0814 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0515\n",
      "Epoch 5: val_loss improved from 1.08144 to 1.05722, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0515 - val_loss: 1.0572 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0282\n",
      "Epoch 6: val_loss improved from 1.05722 to 1.02187, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0282 - val_loss: 1.0219 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0027\n",
      "Epoch 7: val_loss improved from 1.02187 to 1.00491, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0027 - val_loss: 1.0049 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9814\n",
      "Epoch 8: val_loss improved from 1.00491 to 0.97638, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9814 - val_loss: 0.9764 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9656\n",
      "Epoch 9: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9656 - val_loss: 1.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9756\n",
      "Epoch 10: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9756 - val_loss: 0.9875 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train(\n",
    "    model=MODEL,\n",
    "    dataset_path=TRAIN_DATA_PATH,\n",
    "    epochs=EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc4022",
   "metadata": {},
   "source": [
    "### Option 2. Create datasets with train/val/test splits saved as separate files and train on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(\n",
    "    dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ege/recovar/reproducibility/direct_trainer.py:541: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metadata_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples before subsampling: EQ=1030231, NO=235426\n",
      "No noise percentages specified. Creating full dataset with all available samples...\n",
      "\n",
      "Creating train/val/test splits for: FULL_DATASET_SUBSAMPLED_100\n",
      "Total samples: 1265657 (EQ: 1030231, NO: 235426)\n",
      "Processed 1/4943 batches...\n",
      "Processed 11/4943 batches...\n",
      "Processed 21/4943 batches...\n",
      "Processed 31/4943 batches...\n"
     ]
    }
   ],
   "source": [
    "trainer.create_subsampled_datasets(\n",
    "    dataset='stead',\n",
    "    output_dir='preprocessed_data/stead_splits',\n",
    "    noise_percentages=[], \n",
    "    subsampling_factor=1, \n",
    "    maintain_constant_size=False,\n",
    "    save_train_val_test_splits=True, \n",
    "    val_ratio=0.2, \n",
    "    test_ratio=0.3,\n",
    "    random_state_mode='pseudorandom',\n",
    "    base_random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c88046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RepresentationLearningMultipleAutoencoder()\n",
    "\n",
    "history = trainer.train(\n",
    "    model=model,\n",
    "    train_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_train.hdf5',\n",
    "    val_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_val.hdf5',\n",
    "    test_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_test.hdf5',  # Optional\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    use_hdf5_generator=True  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RECOVAR_EGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
