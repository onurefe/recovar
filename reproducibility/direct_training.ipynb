{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cfd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:34:41.910230: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-04 17:34:41.928617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-04 17:34:41.928636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-04 17:34:41.928648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-04 17:34:41.932231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from direct_trainer import DirectTrainer\n",
    "from recovar import RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder\n",
    "from config import (STEAD_TIME_WINDOW, INSTANCE_TIME_WINDOW, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feaf54af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:34:53.920197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.943062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.943195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:53.944396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:34:54.219366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22141 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'stead'\n",
    "MODEL = RepresentationLearningMultipleAutoencoder()\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/ege/recovar_data_preprocessed/stead_pseudorandom_state_ne_subsampled/SUBSAMPLED_100_NOISE_40.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa67e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b19bb",
   "metadata": {},
   "source": [
    "### Option 1. Preprocess the whole data, load it into memory and separate train/val files from there on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.create_subsampled_datasets(\n",
    " #   dataset='stead',\n",
    "  #  output_dir=PREPROCESSED_DATASET_DIRECTORY,\n",
    "   # noise_percentages=[0, 10, 20, 90, 100],\n",
    "    #subsampling_factor=1.0, \n",
    "    #maintain_constant_size=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6092e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 176448 samples (EQ: 105879, NO: 70569)\n",
      "Val: 58816 samples (EQ: 35293, NO: 23523)\n",
      "\n",
      "Starting training...\n",
      "Train samples: 176448\n",
      "Val samples: 58816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:25.498332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:45.324651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f0f3790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-04 17:09:45.324669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2025-07-04 17:09:45.332786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-04 17:09:45.404756: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - ETA: 0s - loss: 1.6378\n",
      "Epoch 1: val_loss improved from inf to 1.45220, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 119s 139ms/step - loss: 1.6378 - val_loss: 1.4522 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.3034\n",
      "Epoch 2: val_loss improved from 1.45220 to 1.25263, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.3034 - val_loss: 1.2526 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.1491\n",
      "Epoch 3: val_loss improved from 1.25263 to 1.22802, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.1491 - val_loss: 1.2280 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0843\n",
      "Epoch 4: val_loss improved from 1.22802 to 1.08144, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0843 - val_loss: 1.0814 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0515\n",
      "Epoch 5: val_loss improved from 1.08144 to 1.05722, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0515 - val_loss: 1.0572 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0282\n",
      "Epoch 6: val_loss improved from 1.05722 to 1.02187, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0282 - val_loss: 1.0219 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0027\n",
      "Epoch 7: val_loss improved from 1.02187 to 1.00491, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0027 - val_loss: 1.0049 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9814\n",
      "Epoch 8: val_loss improved from 1.00491 to 0.97638, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9814 - val_loss: 0.9764 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9656\n",
      "Epoch 9: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9656 - val_loss: 1.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9756\n",
      "Epoch 10: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9756 - val_loss: 0.9875 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train(\n",
    "    model=MODEL,\n",
    "    dataset_path=TRAIN_DATA_PATH,\n",
    "    epochs=EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc4022",
   "metadata": {},
   "source": [
    "### Option 2. Create datasets with train/val/test splits saved as separate files and train on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(\n",
    "    dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb5338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ege/recovar/reproducibility/direct_trainer.py:541: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metadata_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples before subsampling: EQ=1030231, NO=235426\n",
      "No noise percentages specified. Creating full dataset with all available samples...\n",
      "\n",
      "Creating train/val/test splits for: FULL_DATASET_SUBSAMPLED_100\n",
      "Total samples: 1265657 (EQ: 1030231, NO: 235426)\n",
      "Processed 1/4943 batches...\n",
      "Processed 11/4943 batches...\n",
      "Processed 21/4943 batches...\n",
      "Processed 31/4943 batches...\n",
      "Processed 41/4943 batches...\n",
      "Processed 51/4943 batches...\n",
      "Processed 61/4943 batches...\n",
      "Processed 71/4943 batches...\n",
      "Processed 81/4943 batches...\n",
      "Processed 91/4943 batches...\n",
      "Processed 101/4943 batches...\n",
      "Processed 111/4943 batches...\n",
      "Processed 121/4943 batches...\n",
      "Processed 131/4943 batches...\n",
      "Processed 141/4943 batches...\n",
      "Processed 151/4943 batches...\n",
      "Processed 161/4943 batches...\n",
      "Processed 171/4943 batches...\n",
      "Processed 181/4943 batches...\n",
      "Processed 191/4943 batches...\n",
      "Processed 201/4943 batches...\n",
      "Processed 211/4943 batches...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_subsampled_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_data/stead_splits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_percentages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubsampling_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaintain_constant_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_train_val_test_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpseudorandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_random_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recovar/reproducibility/direct_trainer.py:136\u001b[0m, in \u001b[0;36mDirectTrainer.create_subsampled_datasets\u001b[0;34m(self, dataset, output_dir, noise_percentages, subsampling_factor, maintain_constant_size, random_state_mode, base_random_state, save_train_val_test_splits, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m    134\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFULL_DATASET_SUBSAMPLED_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(subsampling_factor\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_train_val_test_splits:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_train_val_test_splits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq_hdf5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_hdf5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_random_state\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_preprocessed_dataset(\n\u001b[1;32m    143\u001b[0m         combined_metadata, eq_hdf5_path, no_hdf5_path,\n\u001b[1;32m    144\u001b[0m         Path(output_dir) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n",
      "File \u001b[0;32m~/recovar/reproducibility/direct_trainer.py:478\u001b[0m, in \u001b[0;36mDirectTrainer._save_train_val_test_splits\u001b[0;34m(self, metadata, eq_hdf5_path, no_hdf5_path, output_base_path, val_ratio, test_ratio, random_state)\u001b[0m\n\u001b[1;32m    476\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[0;32m--> 478\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    480\u001b[0m     X_all[sample_idx:sample_idx\u001b[38;5;241m+\u001b[39mbatch_size] \u001b[38;5;241m=\u001b[39m X_batch\n",
      "File \u001b[0;32m~/recovar/reproducibility/data_generator.py:134\u001b[0m, in \u001b[0;36mBatchGenerator.get_batch\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    idx (int): Index of the batch.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m        and y_batch is the batch of labels.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m batch_waveforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaveforms[\n\u001b[1;32m    131\u001b[0m     (idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size) : ((idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    132\u001b[0m ]\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batchx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_waveforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batchy(batch_waveforms)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_batch\n",
      "File \u001b[0;32m~/recovar/reproducibility/data_generator.py:196\u001b[0m, in \u001b[0;36mBatchGenerator._get_batchx\u001b[0;34m(self, batch_waveforms)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m waveform \u001b[38;5;129;01min\u001b[39;00m batch_waveforms:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m waveform[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m         x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_pick\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrace_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m waveform[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    199\u001b[0m         x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_noise[waveform[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/h5py/_hl/group.py:360\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 360\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5i.pyx:44\u001b[0m, in \u001b[0;36mh5py.h5i.wrap_identifier\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.create_subsampled_datasets(\n",
    "    dataset='stead',\n",
    "    output_dir='preprocessed_data/stead_splits',\n",
    "    noise_percentages=[], \n",
    "    subsampling_factor=1, \n",
    "    maintain_constant_size=False,\n",
    "    save_train_val_test_splits=True, \n",
    "    val_ratio=0.2, \n",
    "    test_ratio=0.3,\n",
    "    random_state_mode='pseudorandom',\n",
    "    base_random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c88046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Train batches: 2\n",
      "Val batches: 1\n",
      "Using HDF5Generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:53:06.122107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:53:24.424524: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbae400de00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-04 17:53:24.424539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2025-07-04 17:53:24.427643: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-04 17:53:24.474209: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 2.7898 \n",
      "Epoch 1: val_loss improved from inf to 2.42737, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 27s 5s/step - loss: 2.7898 - val_loss: 2.4274 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.6873\n",
      "Epoch 2: val_loss improved from 2.42737 to 2.38013, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 300ms/step - loss: 2.6873 - val_loss: 2.3801 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5792\n",
      "Epoch 3: val_loss improved from 2.38013 to 2.33944, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 296ms/step - loss: 2.5792 - val_loss: 2.3394 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4917\n",
      "Epoch 4: val_loss improved from 2.33944 to 2.32055, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 301ms/step - loss: 2.4917 - val_loss: 2.3206 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4460\n",
      "Epoch 5: val_loss improved from 2.32055 to 2.30861, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 1s 650ms/step - loss: 2.4460 - val_loss: 2.3086 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3942\n",
      "Epoch 6: val_loss improved from 2.30861 to 2.29202, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 2.3942 - val_loss: 2.2920 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3677\n",
      "Epoch 7: val_loss improved from 2.29202 to 2.26888, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 298ms/step - loss: 2.3677 - val_loss: 2.2689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3685\n",
      "Epoch 8: val_loss improved from 2.26888 to 2.25247, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 301ms/step - loss: 2.3685 - val_loss: 2.2525 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3015\n",
      "Epoch 9: val_loss improved from 2.25247 to 2.24061, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 354ms/step - loss: 2.3015 - val_loss: 2.2406 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2790\n",
      "Epoch 10: val_loss improved from 2.24061 to 2.23684, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 303ms/step - loss: 2.2790 - val_loss: 2.2368 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2434\n",
      "Epoch 11: val_loss did not improve from 2.23684\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 2.2434 - val_loss: 2.2443 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2146\n",
      "Epoch 12: val_loss improved from 2.23684 to 2.23151, saving model to checkpoints/FULL_DATASET_SUBSAMPLED_0_train_best_model.h5\n",
      "2/2 [==============================] - 0s 299ms/step - loss: 2.2146 - val_loss: 2.2315 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2036\n",
      "Epoch 13: val_loss did not improve from 2.23151\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 2.2036 - val_loss: 2.2406 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1535\n",
      "Epoch 14: val_loss did not improve from 2.23151\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 2.1535 - val_loss: 2.2581 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1212\n",
      "Epoch 15: val_loss did not improve from 2.23151\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 2.1212 - val_loss: 2.2859 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0842\n",
      "Epoch 16: val_loss did not improve from 2.23151\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 2.0842 - val_loss: 2.3005 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0664\n",
      "Epoch 17: val_loss did not improve from 2.23151\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 2.0664 - val_loss: 2.3097 - lr: 5.0000e-04\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = RepresentationLearningMultipleAutoencoder()\n",
    "\n",
    "history = trainer.train(\n",
    "    model=model,\n",
    "    train_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_train.hdf5',\n",
    "    val_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_val.hdf5',\n",
    "    test_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_test.hdf5',  # Optional\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    use_hdf5_generator=True  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RECOVAR_EGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
