{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 15:48:41.186919: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 15:48:41.205379: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-06 15:48:41.205396: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-06 15:48:41.205406: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-06 15:48:41.208978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from itertools import combinations\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from recovar import (\n",
    "    RepresentationLearningSingleAutoencoder, \n",
    "    RepresentationLearningDenoisingSingleAutoencoder, \n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")\n",
    "from config import BATCH_SIZE, WINDOW_SIZE\n",
    "from direct_trainer import HDF5Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Configuration and Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Choose the representation learning model class\n",
    "REPRESENTATION_LEARNING_MODEL_CLASS = RepresentationLearningMultipleAutoencoder\n",
    "\n",
    "# Path to the trained model weights\n",
    "MODEL_WEIGHTS_PATH = \"/home/ege/recovar/reproducibility/checkpoints/stead_full/FULL_STEAD_SUBSAMPLED_100_train_epoch_10.h5\"\n",
    "\n",
    "# Path to the test dataset\n",
    "TEST_DATASET_PATH = \"/home/ege/recovar/reproducibility/preprocessed_data/new_stead/FULL_STEAD_SUBSAMPLED_100_test.hdf5\"\n",
    "\n",
    "# Number of samples to visualize\n",
    "NUM_SAMPLES = 50\n",
    "\n",
    "# Batch size for processing\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20430f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading metadata for crop offset filtering...\")\n",
    "with h5py.File(TEST_DATASET_PATH, 'r') as f:\n",
    "    if 'metadata' in f:\n",
    "        metadata_json = f['metadata'][()].decode('utf-8')\n",
    "        metadata = pd.read_json(metadata_json)\n",
    "        \n",
    "        crop_filter = CropOffsetFilter()\n",
    "        filtered_metadata = crop_filter.apply(metadata)\n",
    "        \n",
    "        #Get indices that passed the filter\n",
    "        filtered_indices = filtered_metadata.index.values\n",
    "        \n",
    "        print(f\"Crop offset filter: {len(filtered_indices)}/{len(metadata)} samples passed\")\n",
    "    else:\n",
    "        print(\"Warning: No metadata found in HDF5 file. Skipping crop offset filter.\")\n",
    "        apply_crop_offset_filter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define Utility Functions\n",
    "# -------------------------------\n",
    "\n",
    "def compute_covariance(data_arrays):\n",
    "    \"\"\"\n",
    "    Computes autocovariance or cross-covariance between signals.\n",
    "    \n",
    "    Args:\n",
    "        data_arrays (np.ndarray): Variable number of 2D arrays, each with shape (timesteps, channels)\n",
    "    \n",
    "    Returns:\n",
    "        lags (np.ndarray): Lag values\n",
    "        avg_cov (np.ndarray): Averaged covariance\n",
    "    \"\"\"\n",
    "    if (len(np.shape(data_arrays)) == 2):\n",
    "        data_arrays = np.expand_dims(data_arrays, axis=0)\n",
    "    \n",
    "    num_signals = len(data_arrays)    \n",
    "    num_timesteps, num_channels = data_arrays[0].shape\n",
    "\n",
    "    covariances = []\n",
    "    lags = np.arange(-num_timesteps + 1, num_timesteps)\n",
    "\n",
    "    if num_signals == 1:\n",
    "        # Autocovariance\n",
    "        data = data_arrays[0]\n",
    "        for c in range(num_channels):\n",
    "            channel_data = data[:, c]\n",
    "            channel_data = channel_data - np.mean(channel_data)  # Zero-mean\n",
    "            cov = np.correlate(channel_data, channel_data, mode='full')\n",
    "            covariances.append(cov)\n",
    "    else:\n",
    "        # Cross-covariance between all possible pairs\n",
    "        pairs = list(combinations(range(num_signals), 2))\n",
    "        for idx1, idx2 in pairs:\n",
    "            data1 = data_arrays[idx1]\n",
    "            data2 = data_arrays[idx2]\n",
    "            for c in range(num_channels):\n",
    "                channel_data1 = data1[:, c]\n",
    "                channel_data2 = data2[:, c]\n",
    "                channel_data1 = channel_data1 - np.mean(channel_data1)  # Zero-mean\n",
    "                channel_data2 = channel_data2 - np.mean(channel_data2)  # Zero-mean\n",
    "                cov = np.correlate(channel_data1, channel_data2, mode='full')\n",
    "                covariances.append(cov)\n",
    "\n",
    "    covariances = np.array(covariances)\n",
    "    avg_cov = np.mean(covariances, axis=0)\n",
    "    return lags, avg_cov\n",
    "\n",
    "def plot_waveform_channel(ax, timesteps, waveform, channel_idx, ylim_min=None, ylim_max=None, color='blue', show_xticks=True):\n",
    "    \"\"\"\n",
    "    Plots a single waveform channel on the given axes.\n",
    "    \"\"\"\n",
    "    channels = ['E', 'N', 'Z']\n",
    "    ax.plot(timesteps, waveform, color=color, linewidth=1)\n",
    "    if channel_idx == 0:\n",
    "        ax.set_title(\"Waveform\", fontsize=14, pad=5, fontweight='bold')\n",
    "        \n",
    "    if ylim_min != None and ylim_max != None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    if show_xticks:\n",
    "        ax.set_xlabel('Timesteps', fontsize=12)\n",
    "        ax.tick_params(axis='x', labelsize=10)\n",
    "    else:\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "def plot_heatmap(ax, heatmap, vmin=None, vmax=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots the heatmap on the given axes.\n",
    "    \"\"\"\n",
    "    if vmin != None and vmax != None:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower')\n",
    "        \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Timesteps', fontsize=12)\n",
    "    ax.set_ylabel('Channels', fontsize=12)\n",
    "    plt.colorbar(cax, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "def plot_autocovariance(ax, lags, autocov, ylim_min=None, ylim_max=None, title=None, ylabel='Autocovariance'):\n",
    "    \"\"\"\n",
    "    Plots the autocovariance function on the given axes.\n",
    "    \"\"\"\n",
    "    if ylim_min != None and ylim_max != None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "        \n",
    "    ax.plot(lags, autocov)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Lag', fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load the model and weights.\n",
    "    \"\"\"\n",
    "    # Initialize the representation learning model\n",
    "    model = REPRESENTATION_LEARNING_MODEL_CLASS()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "    # Build the model (lazy building)\n",
    "    dummy_input = tf.zeros((1, 3000, 3))\n",
    "    model(dummy_input)\n",
    "\n",
    "    # Load the pre-trained weights\n",
    "    if Path(MODEL_WEIGHTS_PATH).exists():\n",
    "        model.load_weights(MODEL_WEIGHTS_PATH)\n",
    "        print(f\"Loaded weights from: {MODEL_WEIGHTS_PATH}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model weights not found at: {MODEL_WEIGHTS_PATH}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_sample_data_direct(test_dataset_path, num_samples):\n",
    "    \"\"\"\n",
    "    Load sample data using the direct method (from HDF5 file).\n",
    "    \n",
    "    Returns:\n",
    "        waveforms (np.ndarray): Shape (num_samples, 3000, 3)\n",
    "        labels (np.ndarray): Shape (num_samples)\n",
    "        metadata (pd.DataFrame or None): Metadata if available\n",
    "    \"\"\"\n",
    "    # Use HDF5Generator to load data\n",
    "    test_gen = HDF5Generator(test_dataset_path, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Load metadata if available\n",
    "    metadata = None\n",
    "    with h5py.File(test_dataset_path, 'r') as f:\n",
    "        if 'metadata' in f:\n",
    "            metadata_json = f['metadata'][()].decode('utf-8')\n",
    "            metadata = pd.read_json(metadata_json)\n",
    "            print(f\"Loaded metadata with {len(metadata)} samples\")\n",
    "    \n",
    "    # Calculate number of batches needed\n",
    "    num_batches = min((num_samples + BATCH_SIZE - 1) // BATCH_SIZE, len(test_gen))\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Load data batch by batch\n",
    "    for i in range(num_batches):\n",
    "        x_batch, y_batch = test_gen[i]\n",
    "        X.append(x_batch)\n",
    "        Y.append(y_batch)\n",
    "        \n",
    "        # Break if we have enough samples\n",
    "        if sum(len(x) for x in X) >= num_samples:\n",
    "            break\n",
    "    \n",
    "    # Concatenate and trim to exact number of samples\n",
    "    X = np.concatenate(X, axis=0)[:num_samples]\n",
    "    Y = np.concatenate(Y, axis=0)[:num_samples]\n",
    "    \n",
    "    print(f\"Loaded {len(X)} samples\")\n",
    "    print(f\"Earthquake samples: {np.sum(Y == 1)}\")\n",
    "    print(f\"Noise samples: {np.sum(Y == 0)}\")\n",
    "    \n",
    "    return X, Y, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from: /home/ege/recovar/reproducibility/checkpoints/stead_full/FULL_STEAD_SUBSAMPLED_100_train_epoch_10.h5\n",
      "Loaded metadata with 253132 samples\n",
      "Loaded 50 samples\n",
      "Earthquake samples: 42\n",
      "Noise samples: 8\n",
      "Feature maps shape: (50, 5, 94, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load the model and data\n",
    "model = load_model()\n",
    "waveforms, labels, metadata = load_sample_data_direct(TEST_DATASET_PATH, NUM_SAMPLES)\n",
    "\n",
    "# Get latent representations\n",
    "if REPRESENTATION_LEARNING_MODEL_CLASS == RepresentationLearningMultipleAutoencoder:\n",
    "    model_out = model(waveforms)\n",
    "    feature_maps = list(model_out)[0:5]  # Get the 5 feature maps\n",
    "    feature_maps = np.array(feature_maps)\n",
    "else:\n",
    "    model_out = model(waveforms)\n",
    "    feature_maps = list(model_out)[0:1]  # Get single feature map\n",
    "    feature_maps = np.array(feature_maps)\n",
    "    \n",
    "# Transpose to have batch dimension first\n",
    "feature_maps = np.transpose(feature_maps, axes=[1, 0, 2, 3])\n",
    "\n",
    "print(f\"Feature maps shape: {feature_maps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize latent representations for earthquake vs noise samples\n",
    "WAVEFORM_COLORS = ['blue', 'green', 'red']  # For E, N, Z channels\n",
    "\n",
    "# Separate earthquake and noise indices\n",
    "earthquake_indices = [i for i, label in enumerate(labels) if label > 0.5]\n",
    "noise_indices = [i for i, label in enumerate(labels) if label <= 0.5]\n",
    "\n",
    "# Ensure we have both earthquake and noise samples\n",
    "NUM_PLOTS = min(len(earthquake_indices), len(noise_indices), 10)  # Limit to 10 plots\n",
    "\n",
    "if NUM_PLOTS == 0:\n",
    "    print(\"Not enough earthquake or noise samples to create comparison plots.\")\n",
    "else:\n",
    "    print(f\"Creating {NUM_PLOTS} comparison plots...\")\n",
    "\n",
    "for plot_idx in range(NUM_PLOTS):\n",
    "    eq_idx = earthquake_indices[plot_idx]\n",
    "    noise_idx = noise_indices[plot_idx]\n",
    "    \n",
    "    # Extract earthquake data\n",
    "    eq_waveform = waveforms[eq_idx]\n",
    "    eq_feature_map = feature_maps[eq_idx]\n",
    "    lags_waveform_eq, autocov_waveform_eq = compute_covariance(eq_waveform)\n",
    "    lags_heatmap_eq, autocov_heatmap_eq = compute_covariance(eq_feature_map)\n",
    "    \n",
    "    # Extract noise data\n",
    "    noise_waveform = waveforms[noise_idx]\n",
    "    noise_feature_map = feature_maps[noise_idx]\n",
    "    lags_waveform_noise, autocov_waveform_noise = compute_covariance(noise_waveform)\n",
    "    lags_heatmap_noise, autocov_heatmap_noise = compute_covariance(noise_feature_map)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    main_gs = GridSpec(1, 2, figure=fig, wspace=0.3)\n",
    "    \n",
    "    # --- Earthquake Column ---\n",
    "    eq_gs = main_gs[0, 0].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "    \n",
    "    # Top-Left: Waveform Channels\n",
    "    eq_waveform_gs = eq_gs[0, 0].subgridspec(eq_waveform.shape[1], 1, hspace=0.3)\n",
    "    timesteps_eq = np.arange(eq_waveform.shape[0])\n",
    "    \n",
    "    for channel in range(eq_waveform.shape[1]):\n",
    "        ax = fig.add_subplot(eq_waveform_gs[channel, 0])\n",
    "        show_xticks = (channel == eq_waveform.shape[1] - 1)\n",
    "        plot_waveform_channel(ax, timesteps_eq, eq_waveform[:, channel], channel, \n",
    "                              color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                              show_xticks=show_xticks)\n",
    "    \n",
    "    # Top-Right: Heatmap\n",
    "    ax_heatmap_eq = fig.add_subplot(eq_gs[0, 1])\n",
    "    plot_heatmap(ax_heatmap_eq, eq_feature_map[0].T, title=\"Latent Representation\")\n",
    "    \n",
    "    # Bottom-Left: Autocovariance of Waveform\n",
    "    ax_autocov_waveform_eq = fig.add_subplot(eq_gs[1, 0])\n",
    "    plot_autocovariance(ax_autocov_waveform_eq, lags_waveform_eq, autocov_waveform_eq, \n",
    "                        title='Waveform\\nAutocovariance function')\n",
    "    \n",
    "    if REPRESENTATION_LEARNING_MODEL_CLASS == RepresentationLearningMultipleAutoencoder:\n",
    "        latent_covariance_title = 'Latent Representation\\nCross-covariance function'\n",
    "        latent_covariance_ylabel = 'Mean Cross-covariance'\n",
    "    else:\n",
    "        latent_covariance_title = 'Latent Representation\\nAuto-covariance function'\n",
    "        latent_covariance_ylabel = 'Auto-covariance'\n",
    "        \n",
    "    # Bottom-Right: Autocovariance of Heatmap\n",
    "    ax_autocov_heatmap_eq = fig.add_subplot(eq_gs[1, 1])\n",
    "    plot_autocovariance(ax_autocov_heatmap_eq, lags_heatmap_eq, autocov_heatmap_eq, \n",
    "                        title=latent_covariance_title,\n",
    "                        ylabel=latent_covariance_ylabel)\n",
    "    \n",
    "    # --- Noise Column ---\n",
    "    # Use same scale limits for noise plots\n",
    "    feature_map_max = np.max(eq_feature_map[0], axis=(0, 1))\n",
    "    feature_map_min = np.min(eq_feature_map[0], axis=(0, 1))\n",
    "    \n",
    "    autocov_heatmap_max = np.max(autocov_heatmap_eq, axis=(0))\n",
    "    autocov_heatmap_min = np.min(autocov_heatmap_eq, axis=(0))\n",
    "    \n",
    "    noise_gs = main_gs[0, 1].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "    \n",
    "    # Top-Left: Waveform Channels\n",
    "    noise_waveform_gs = noise_gs[0, 0].subgridspec(noise_waveform.shape[1], 1, hspace=0.3)\n",
    "    timesteps_noise = np.arange(noise_waveform.shape[0])\n",
    "    \n",
    "    for channel in range(noise_waveform.shape[1]):\n",
    "        ax = fig.add_subplot(noise_waveform_gs[channel, 0])\n",
    "        show_xticks = (channel == noise_waveform.shape[1] - 1)\n",
    "        plot_waveform_channel(ax, timesteps_noise, noise_waveform[:, channel], channel, \n",
    "                              color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                              show_xticks=show_xticks)\n",
    "    \n",
    "    # Top-Right: Heatmap\n",
    "    ax_heatmap_noise = fig.add_subplot(noise_gs[0, 1])\n",
    "    plot_heatmap(ax_heatmap_noise, noise_feature_map[0].T, feature_map_min, feature_map_max, \"Latent Representation\")\n",
    "    \n",
    "    # Bottom-Left: Autocovariance of Waveform\n",
    "    ax_autocov_waveform_noise = fig.add_subplot(noise_gs[1, 0])\n",
    "    plot_autocovariance(ax_autocov_waveform_noise, \n",
    "                        lags_waveform_noise, \n",
    "                        autocov_waveform_noise, \n",
    "                        title='Waveform\\nAutocovariance function')\n",
    "    \n",
    "    # Bottom-Right: Autocovariance of Heatmap\n",
    "    ax_autocov_heatmap_noise = fig.add_subplot(noise_gs[1, 1])\n",
    "    plot_autocovariance(ax_autocov_heatmap_noise, \n",
    "                        lags_heatmap_noise, \n",
    "                        autocov_heatmap_noise,\n",
    "                        autocov_heatmap_min,\n",
    "                        autocov_heatmap_max,\n",
    "                        latent_covariance_title,\n",
    "                        latent_covariance_ylabel)\n",
    "    \n",
    "    # Add column titles\n",
    "    fig.text(0.30, 0.935, 'Earthquake sample', ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    fig.text(0.725, 0.935, 'Noise sample', ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path(\"latent_visualizations_direct\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    output_path = output_dir / f\"latent_plot_pair_{plot_idx + 1}.png\"\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved plot {plot_idx + 1} to {output_path}\")\n",
    "\n",
    "print(\"\\nLatent space visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Plot average latent representations for earthquake vs noise\n",
    "if len(earthquake_indices) > 0 and len(noise_indices) > 0:\n",
    "    # Get average feature maps\n",
    "    eq_feature_maps = feature_maps[earthquake_indices[:min(50, len(earthquake_indices))]]\n",
    "    noise_feature_maps = feature_maps[noise_indices[:min(50, len(noise_indices))]]\n",
    "    \n",
    "    avg_eq_feature = np.mean(eq_feature_maps[:, 0, :, :], axis=0)\n",
    "    avg_noise_feature = np.mean(noise_feature_maps[:, 0, :, :], axis=0)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Average earthquake latent representation\n",
    "    im1 = axes[0].imshow(avg_eq_feature.T, aspect='auto', cmap='magma', origin='lower')\n",
    "    axes[0].set_title('Average Earthquake\\nLatent Representation', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Timesteps')\n",
    "    axes[0].set_ylabel('Channels')\n",
    "    plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Average noise latent representation\n",
    "    im2 = axes[1].imshow(avg_noise_feature.T, aspect='auto', cmap='magma', origin='lower')\n",
    "    axes[1].set_title('Average Noise\\nLatent Representation', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Timesteps')\n",
    "    axes[1].set_ylabel('Channels')\n",
    "    plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Difference\n",
    "    diff = avg_eq_feature - avg_noise_feature\n",
    "    im3 = axes[2].imshow(diff.T, aspect='auto', cmap='RdBu_r', origin='lower')\n",
    "    axes[2].set_title('Difference\\n(Earthquake - Noise)', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_xlabel('Timesteps')\n",
    "    axes[2].set_ylabel('Channels')\n",
    "    plt.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_path = Path(\"latent_visualizations_direct\") / \"average_latent_comparison.png\"\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved average comparison to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using multiple autoencoders, visualize differences between them\n",
    "if REPRESENTATION_LEARNING_MODEL_CLASS == RepresentationLearningMultipleAutoencoder and len(earthquake_indices) > 0:\n",
    "    sample_idx = earthquake_indices[0]  # Take first earthquake sample\n",
    "    sample_features = feature_maps[sample_idx]  # Shape: (5, 94, 64)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot each autoencoder's representation\n",
    "    for i in range(min(5, sample_features.shape[0])):\n",
    "        im = axes[i].imshow(sample_features[i].T, aspect='auto', cmap='magma', origin='lower')\n",
    "        axes[i].set_title(f'Autoencoder {i+1}\\nLatent Representation', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel('Timesteps')\n",
    "        axes[i].set_ylabel('Channels')\n",
    "        plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    plt.suptitle('Multiple Autoencoder Representations for Single Earthquake Sample', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RECOVAR_EGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
