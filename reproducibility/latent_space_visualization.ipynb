{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 11:43:10.036302: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-18 11:43:10.038319: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-18 11:43:10.065394: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-18 11:43:10.065418: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-18 11:43:10.065436: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-18 11:43:10.070612: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-18 11:43:10.071320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-18 11:43:10.735305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from recovar import (RepresentationLearningSingleAutoencoder, \n",
    "                     RepresentationLearningDenoisingSingleAutoencoder, \n",
    "                     RepresentationLearningMultipleAutoencoder)\n",
    "\n",
    "from directory import get_checkpoint_path\n",
    "from config import BATCH_SIZE, N_CHANNELS\n",
    "from kfold_environment import KFoldEnvironment\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Configuration and Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Experiment name identifier\n",
    "EXP_NAME = \"exp_test\"\n",
    "\n",
    "# Choose the representation learning model class\n",
    "REPRESENTATION_LEARNING_MODEL_CLASS = RepresentationLearningMultipleAutoencoder\n",
    "\n",
    "# Specify training and testing datasets ('stead' or 'instance')\n",
    "TRAIN_DATASET = \"instance\"\n",
    "TEST_DATASET = \"stead\"\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCH = 6\n",
    "\n",
    "# Data split identifier\n",
    "SPLIT = 0\n",
    "\n",
    "# Num of samples to plot.\n",
    "NUM_SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance(data_arrays):\n",
    "    \"\"\"\n",
    "    Computes autocovariance or cross-covariance between signals.\n",
    "    \n",
    "    Args:\n",
    "        data_arrays (np.ndarray): Variable number of 2D arrays, each with shape (timesteps, channels)\n",
    "    \n",
    "    Returns:\n",
    "        lags (np.ndarray): Lag values\n",
    "        avg_cov (np.ndarray): Averaged covariance\n",
    "    \"\"\"\n",
    "    if (len(np.shape(data_arrays)) == 2):\n",
    "        data_arrays = np.expand_dims(data_arrays,axis=0)\n",
    "    \n",
    "    num_signals = len(data_arrays)    \n",
    "    num_timesteps, num_channels = data_arrays[0].shape\n",
    "\n",
    "    covariances = []\n",
    "    lags = np.arange(-num_timesteps + 1, num_timesteps)\n",
    "\n",
    "    if num_signals == 1:\n",
    "        # Autocovariance\n",
    "        data = data_arrays[0]\n",
    "        for c in range(num_channels):\n",
    "            channel_data = data[:, c]\n",
    "            channel_data = channel_data - np.mean(channel_data)  # Zero-mean\n",
    "            cov = np.correlate(channel_data, channel_data, mode='full')\n",
    "            covariances.append(cov)\n",
    "    else:\n",
    "        # Cross-covariance between all possible pairs\n",
    "        pairs = list(combinations(range(num_signals), 2))\n",
    "        for idx1, idx2 in pairs:\n",
    "            data1 = data_arrays[idx1]\n",
    "            data2 = data_arrays[idx2]\n",
    "            for c in range(num_channels):\n",
    "                channel_data1 = data1[:, c]\n",
    "                channel_data2 = data2[:, c]\n",
    "                channel_data1 = channel_data1 - np.mean(channel_data1)  # Zero-mean\n",
    "                channel_data2 = channel_data2 - np.mean(channel_data2)  # Zero-mean\n",
    "                cov = np.correlate(channel_data1, channel_data2, mode='full')\n",
    "                covariances.append(cov)\n",
    "\n",
    "    covariances = np.array(covariances)\n",
    "    avg_cov = np.mean(covariances, axis=0)\n",
    "    return lags, avg_cov\n",
    "\n",
    "def plot_waveform_channel(ax, timesteps, waveform, channel_idx, ylim_min=None, ylim_max=None, color='blue', show_xticks=True):\n",
    "    \"\"\"\n",
    "    Plots a single waveform channel on the given axes.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axes to plot on\n",
    "        timesteps (np.ndarray): Array of timesteps\n",
    "        waveform (np.ndarray): Waveform data for one channel\n",
    "        channel_idx (int): Channel index (0-based)\n",
    "        color (str): Color for the plot\n",
    "        show_xticks (bool): Whether to show x-axis tick labels and label\n",
    "    \"\"\"\n",
    "    channels =['E', 'N', 'Z']\n",
    "    ax.plot(timesteps, waveform, color=color, linewidth=1)\n",
    "    if channel_idx == 0:\n",
    "        ax.set_title(\"Waveform\", fontsize=14, pad=5, fontweight='bold')\n",
    "        \n",
    "    if ylim_min != None and ylim_max != None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    if show_xticks:\n",
    "        ax.set_xlabel('Timesteps', fontsize=12)\n",
    "        ax.tick_params(axis='x', labelsize=10)\n",
    "    else:\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "def plot_heatmap(ax, heatmap, vmin=None, vmax=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots the heatmap on the given axes.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axes to plot on\n",
    "        heatmap (np.ndarray): Shape (94, 64)\n",
    "    \"\"\"\n",
    "    if vmin != None and vmax != None:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower')\n",
    "        \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Timesteps', fontsize=12)\n",
    "    ax.set_ylabel('Channels', fontsize=12)\n",
    "    plt.colorbar(cax, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "def plot_autocovariance(ax, lags, autocov,  ylim_min=None, ylim_max=None, title=None, ylabel='Autocovariance'):\n",
    "    \"\"\"\n",
    "    Plots the autocovariance function on the given axes.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axes to plot on\n",
    "        lags (np.ndarray): Lag values\n",
    "        autocov (np.ndarray): Autocovariance values\n",
    "        title (str): Title of the plot\n",
    "    \"\"\"\n",
    "    if ylim_min != None and ylim_max != None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "        \n",
    "    ax.plot(lags, autocov)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Lag', fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "\n",
    "def load_model():\n",
    "    # Initialize the representation learning model\n",
    "    model = REPRESENTATION_LEARNING_MODEL_CLASS()\n",
    "    model.compile()\n",
    "\n",
    "    # Perform a forward pass with random input to initialize model weights\n",
    "    model(np.random.normal(size=[BATCH_SIZE, 3000, N_CHANNELS]))\n",
    "\n",
    "    # Construct the checkpoint path for the model weights\n",
    "    cp_path = get_checkpoint_path(\n",
    "        EXP_NAME,\n",
    "        REPRESENTATION_LEARNING_MODEL_CLASS().name,\n",
    "        TRAIN_DATASET,\n",
    "        SPLIT,\n",
    "        EPOCH\n",
    "    )\n",
    "\n",
    "    # Load the pre-trained weights into the model\n",
    "    model.load_weights(cp_path)\n",
    "    return model\n",
    "\n",
    "def load_sample_data():\n",
    "    \"\"\"\n",
    "    Generates sample waveform and heatmap data.\n",
    "    \n",
    "    Returns:\n",
    "        waveform (np.ndarray): Shape (NUM_SAMPLES, 3000, 3)\n",
    "        labels (np.ndarray): Shape (NUM_SAMPLES)\n",
    "        metadata (dataframe)\n",
    "    \"\"\"\n",
    "    # Create a K-Fold environment for the specified test dataset\n",
    "    kenv = KFoldEnvironment(TEST_DATASET)\n",
    "\n",
    "    # Retrieve metadata for training, validation, and testing splits\n",
    "    __, __, test_metadata = kenv.get_split_metadata(SPLIT)\n",
    "\n",
    "    # Retrieve data generators for training, validation, and testing\n",
    "    __, __, test_gen, __ = kenv.get_generators(SPLIT)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Data Preparation\n",
    "    # -------------------------------\n",
    "\n",
    "    # Initialize lists to hold batches of data\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    num_batches = 1 + (NUM_SAMPLES // BATCH_SIZE)\n",
    "    \n",
    "    # Iterate over the test generator.\n",
    "    for i in range(num_batches):\n",
    "        x_batch, y_batch = test_gen.__getitem__(i)\n",
    "        X.append(x_batch)\n",
    "        Y.append(y_batch)\n",
    "\n",
    "    # Concatenate all batches into single numpy arrays\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0)\n",
    "    \n",
    "    return X, Y, test_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/onur/seismic_purifier_data/data/stead/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate sample data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m waveforms, labels, metadata \u001b[38;5;241m=\u001b[39m \u001b[43mload_sample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m REPRESENTATION_LEARNING_MODEL_CLASS \u001b[38;5;241m==\u001b[39m RepresentationLearningMultipleAutoencoder:\n",
      "Cell \u001b[0;32mIn[5], line 149\u001b[0m, in \u001b[0;36mload_sample_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mGenerates sample waveform and heatmap data.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    metadata (dataframe)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Create a K-Fold environment for the specified test dataset\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m kenv \u001b[38;5;241m=\u001b[39m \u001b[43mKFoldEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_DATASET\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Retrieve metadata for training, validation, and testing splits\u001b[39;00m\n\u001b[1;32m    152\u001b[0m __, __, test_metadata \u001b[38;5;241m=\u001b[39m kenv\u001b[38;5;241m.\u001b[39mget_split_metadata(SPLIT)\n",
      "File \u001b[0;32m~/Desktop/GitRepos/recovar/reproducibility/kfold_environment.py:130\u001b[0m, in \u001b[0;36mKFoldEnvironment.__init__\u001b[0;34m(self, dataset, preprocessed_dataset_directory, batch_size, stead_time_window, instance_time_window, stead_waveforms_hdf5, stead_metadata_csv, instance_eq_waveforms_hdf5, instance_no_waveforms_hdf5, instance_eq_metadata_csv, instance_no_metadata_csv, model_time_window, phase_ensured_crop_ratio, phase_ensuring_margin, n_splits, n_chunks, subsampling_factor, sampling_freq, train_val_ratio, freqmin, freqmax)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstead\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 130\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_stead_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstead_metadata_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meq_hdf5_path \u001b[38;5;241m=\u001b[39m stead_waveforms_hdf5\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_hdf5_path \u001b[38;5;241m=\u001b[39m stead_waveforms_hdf5\n",
      "File \u001b[0;32m~/Desktop/GitRepos/recovar/reproducibility/kfold_environment.py:389\u001b[0m, in \u001b[0;36mKFoldEnvironment._parse_stead_metadata\u001b[0;34m(self, metadata_csv)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_stead_metadata\u001b[39m(\u001b[38;5;28mself\u001b[39m, metadata_csv):\n\u001b[1;32m    375\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m    Parses the metadata of the STEAD dataset and transforms certain columns in a\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    way to enable generic handling.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m        The dataframe that contains standardized metadata of the STEAD dataset.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    392\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceiver_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation_name\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/envs/recovar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/recovar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/recovar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/recovar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/recovar/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/onur/seismic_purifier_data/data/stead/metadata.csv'"
     ]
    }
   ],
   "source": [
    "# Generate sample data\n",
    "waveforms, labels, metadata = load_sample_data()\n",
    "model = load_model()\n",
    "\n",
    "if REPRESENTATION_LEARNING_MODEL_CLASS == RepresentationLearningMultipleAutoencoder:\n",
    "    model_out = model(waveforms)\n",
    "    feature_maps = list(model_out)[0:5]\n",
    "    feature_maps = np.array(feature_maps)\n",
    "else:\n",
    "    model_out = model(waveforms)\n",
    "    feature_maps = list(model_out)[0:1]\n",
    "    feature_maps = np.array(feature_maps)\n",
    "    \n",
    "feature_maps = np.transpose(feature_maps, axes=[1, 0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
      "/tmp/ipykernel_1156324/2602815668.py:115: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 50  # Adjust as needed\n",
    "WAVEFORM_COLORS = ['blue', 'green', 'red']  # Adjust based on actual channels\n",
    "\n",
    "# Separate earthquake and noise indices\n",
    "earthquake_indices = [i for i, label in enumerate(labels) if label > 0.5]\n",
    "noise_indices = [i for i, label in enumerate(labels) if label <= 0.5]\n",
    "\n",
    "# Ensure equal number of earthquake and noise samples\n",
    "NUM_PLOTS = min(len(earthquake_indices), len(noise_indices), NUM_SAMPLES)\n",
    "\n",
    "for plot_idx in range(NUM_PLOTS):\n",
    "    eq_idx = earthquake_indices[plot_idx]\n",
    "    noise_idx = noise_indices[plot_idx]\n",
    "    \n",
    "    # Extract earthquake data\n",
    "    eq_waveform = waveforms[eq_idx]\n",
    "    eq_feature_map = feature_maps[eq_idx]\n",
    "    lags_waveform_eq, autocov_waveform_eq = compute_covariance(eq_waveform)  # Averaging over channels\n",
    "    lags_heatmap_eq, autocov_heatmap_eq = compute_covariance(eq_feature_map)\n",
    "    \n",
    "    # Extract noise data\n",
    "    noise_waveform = waveforms[noise_idx]\n",
    "    noise_feature_map = feature_maps[noise_idx]\n",
    "    lags_waveform_noise, autocov_waveform_noise = compute_covariance(noise_waveform)  # Averaging over channels\n",
    "    lags_heatmap_noise, autocov_heatmap_noise = compute_covariance(noise_feature_map)\n",
    "    \n",
    "    # Create a figure with a 1x2 grid: left for earthquake, right for noise\n",
    "    fig = plt.figure(figsize=(20, 10))  # Adjust size as needed\n",
    "    main_gs = GridSpec(1, 2, figure=fig, wspace=0.3)\n",
    "    \n",
    "    # --- Earthquake Column ---\n",
    "    eq_gs = main_gs[0, 0].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "    \n",
    "    # Top-Left: Waveform Channels\n",
    "    eq_waveform_gs = eq_gs[0, 0].subgridspec(eq_waveform.shape[1], 1, hspace=0.3)\n",
    "    timesteps_eq = np.arange(eq_waveform.shape[0])\n",
    "    \n",
    "    for channel in range(eq_waveform.shape[1]):\n",
    "        ax = fig.add_subplot(eq_waveform_gs[channel, 0])\n",
    "        show_xticks = (channel == eq_waveform.shape[1] - 1)\n",
    "        plot_waveform_channel(ax, timesteps_eq, eq_waveform[:, channel], channel, \n",
    "                              color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                              show_xticks=show_xticks)\n",
    "    \n",
    "    # Top-Right: Heatmap\n",
    "    ax_heatmap_eq = fig.add_subplot(eq_gs[0, 1])\n",
    "    plot_heatmap(ax_heatmap_eq, eq_feature_map[0].T, title=\"Latent Representation\")\n",
    "    \n",
    "    # Bottom-Left: Autocovariance of Waveform\n",
    "    ax_autocov_waveform_eq = fig.add_subplot(eq_gs[1, 0])\n",
    "    plot_autocovariance(ax_autocov_waveform_eq, lags_waveform_eq, autocov_waveform_eq, \n",
    "                        title='Waveform\\nAutocovariance function')\n",
    "    \n",
    "    if REPRESENTATION_LEARNING_MODEL_CLASS == RepresentationLearningMultipleAutoencoder:\n",
    "        latent_covariance_title = 'Latent Representation\\nCross-covariance function'\n",
    "        latent_covariance_ylabel = 'Mean Cross-covariance'\n",
    "    else:\n",
    "        latent_covariance_title = 'Latent Representation\\nAuto-covariance function'\n",
    "        latent_covariance_ylabel = 'Auto-covariance'\n",
    "        \n",
    "    # Bottom-Right: Autocovariance of Heatmap\n",
    "    ax_autocov_heatmap_eq = fig.add_subplot(eq_gs[1, 1])\n",
    "    plot_autocovariance(ax_autocov_heatmap_eq, lags_heatmap_eq, autocov_heatmap_eq, \n",
    "                        title=latent_covariance_title,\n",
    "                        ylabel=latent_covariance_ylabel)\n",
    "    \n",
    "    # --- Noise Column ---\n",
    "    feature_map_max = np.max(eq_feature_map[0], axis=(0, 1))\n",
    "    feature_map_min = np.min(eq_feature_map[0], axis=(0, 1))\n",
    "    \n",
    "    autocov_heatmap_max = np.max(autocov_heatmap_eq, axis=(0))\n",
    "    autocov_heatmap_min = np.min(autocov_heatmap_eq, axis=(0))\n",
    "    \n",
    "    noise_gs = main_gs[0, 1].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "    \n",
    "    # Top-Left: Waveform Channels\n",
    "    noise_waveform_gs = noise_gs[0, 0].subgridspec(noise_waveform.shape[1], 1, hspace=0.3)\n",
    "    timesteps_noise = np.arange(noise_waveform.shape[0])\n",
    "    \n",
    "    for channel in range(noise_waveform.shape[1]):\n",
    "        ax = fig.add_subplot(noise_waveform_gs[channel, 0])\n",
    "        show_xticks = (channel == noise_waveform.shape[1] - 1)\n",
    "        plot_waveform_channel(ax, timesteps_noise, noise_waveform[:, channel], channel, \n",
    "                              color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                              show_xticks=show_xticks)\n",
    "    \n",
    "    # Top-Right: Heatmap\n",
    "    ax_heatmap_noise = fig.add_subplot(noise_gs[0, 1])\n",
    "    plot_heatmap(ax_heatmap_noise, noise_feature_map[0].T, feature_map_min, feature_map_max, \"Latent Representation\")\n",
    "    \n",
    "    # Bottom-Left: Autocovariance of Waveform\n",
    "    ax_autocov_waveform_noise = fig.add_subplot(noise_gs[1, 0])\n",
    "    plot_autocovariance(ax_autocov_waveform_noise, \n",
    "                        lags_waveform_noise, \n",
    "                        autocov_waveform_noise, \n",
    "                        title='Waveform\\nAutocovariance function')\n",
    "    \n",
    "    # Bottom-Right: Autocovariance of Heatmap\n",
    "    ax_autocov_heatmap_noise = fig.add_subplot(noise_gs[1, 1])\n",
    "    plot_autocovariance(ax_autocov_heatmap_noise, \n",
    "                        lags_heatmap_noise, \n",
    "                        autocov_heatmap_noise,\n",
    "                        autocov_heatmap_min,\n",
    "                        autocov_heatmap_max,\n",
    "                        latent_covariance_title,\n",
    "                        latent_covariance_ylabel)\n",
    "    \n",
    "    # --- Add Column Titles ---\n",
    "    # Positioning the titles above the respective columns\n",
    "    # Adjust the y-coordinate (0.95) if necessary based on your figure's layout\n",
    "    fig.text(0.30, 0.935, 'Earthquake sample', ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    fig.text(0.725, 0.935, 'Noise sample', ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Adjust overall layout and save the figure\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.03, 0.75])  # Adjust rect to accommodate the main title\n",
    "    plt.savefig(f\"latent_plot_pair_{plot_idx + 1}.png\")\n",
    "    plt.close(fig)  # Close the figure to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic_purifier_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
