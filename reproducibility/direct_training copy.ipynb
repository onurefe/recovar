{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cfd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:47:28.971351: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-04 17:47:28.990635: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-04 17:47:28.990658: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-04 17:47:28.990668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-04 17:47:28.994497: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from direct_trainer import DirectTrainer\n",
    "from recovar import RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder\n",
    "from config import (STEAD_TIME_WINDOW, INSTANCE_TIME_WINDOW, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feaf54af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:47:32.996562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.014719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.014819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.015909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.015972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.016013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.307453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.307539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.307592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-04 17:47:33.307633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 864 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'stead'\n",
    "MODEL = RepresentationLearningMultipleAutoencoder()\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/ege/recovar_data_preprocessed/stead_pseudorandom_state_ne_subsampled/SUBSAMPLED_100_NOISE_40.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa67e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b19bb",
   "metadata": {},
   "source": [
    "### Option 1. Preprocess the whole data, load it into memory and separate train/val files from there on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.create_subsampled_datasets(\n",
    " #   dataset='stead',\n",
    "  #  output_dir=PREPROCESSED_DATASET_DIRECTORY,\n",
    "   # noise_percentages=[0, 10, 20, 90, 100],\n",
    "    #subsampling_factor=1.0, \n",
    "    #maintain_constant_size=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6092e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 176448 samples (EQ: 105879, NO: 70569)\n",
      "Val: 58816 samples (EQ: 35293, NO: 23523)\n",
      "\n",
      "Starting training...\n",
      "Train samples: 176448\n",
      "Val samples: 58816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:25.498332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:09:45.324651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f0f3790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-04 17:09:45.324669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2025-07-04 17:09:45.332786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-04 17:09:45.404756: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - ETA: 0s - loss: 1.6378\n",
      "Epoch 1: val_loss improved from inf to 1.45220, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 119s 139ms/step - loss: 1.6378 - val_loss: 1.4522 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.3034\n",
      "Epoch 2: val_loss improved from 1.45220 to 1.25263, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.3034 - val_loss: 1.2526 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.1491\n",
      "Epoch 3: val_loss improved from 1.25263 to 1.22802, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.1491 - val_loss: 1.2280 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0843\n",
      "Epoch 4: val_loss improved from 1.22802 to 1.08144, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0843 - val_loss: 1.0814 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0515\n",
      "Epoch 5: val_loss improved from 1.08144 to 1.05722, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0515 - val_loss: 1.0572 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0282\n",
      "Epoch 6: val_loss improved from 1.05722 to 1.02187, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0282 - val_loss: 1.0219 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.0027\n",
      "Epoch 7: val_loss improved from 1.02187 to 1.00491, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 1.0027 - val_loss: 1.0049 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9814\n",
      "Epoch 8: val_loss improved from 1.00491 to 0.97638, saving model to checkpoints/SUBSAMPLED_100_NOISE_40_best_model.h5\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9814 - val_loss: 0.9764 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9656\n",
      "Epoch 9: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9656 - val_loss: 1.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.9756\n",
      "Epoch 10: val_loss did not improve from 0.97638\n",
      "690/690 [==============================] - 93s 135ms/step - loss: 0.9756 - val_loss: 0.9875 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train(\n",
    "    model=MODEL,\n",
    "    dataset_path=TRAIN_DATA_PATH,\n",
    "    epochs=EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc4022",
   "metadata": {},
   "source": [
    "### Option 2. Create datasets with train/val/test splits saved as separate files and train on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c4dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DirectTrainer(\n",
    "    dataset=DATASET,\n",
    "    dataset_time_window=STEAD_TIME_WINDOW,\n",
    "    model_time_window=WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ege/recovar/reproducibility/direct_trainer.py:541: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metadata_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples before subsampling: EQ=1030231, NO=235426\n",
      "No noise percentages specified. Creating full dataset with all available samples...\n",
      "\n",
      "Creating train/val/test splits for: FULL_DATASET_SUBSAMPLED_100\n",
      "Total samples: 1265657 (EQ: 1030231, NO: 235426)\n",
      "Processed 1/4943 batches...\n",
      "Processed 11/4943 batches...\n",
      "Processed 21/4943 batches...\n",
      "Processed 31/4943 batches...\n",
      "Processed 41/4943 batches...\n",
      "Processed 51/4943 batches...\n",
      "Processed 61/4943 batches...\n",
      "Processed 71/4943 batches...\n",
      "Processed 81/4943 batches...\n",
      "Processed 91/4943 batches...\n"
     ]
    }
   ],
   "source": [
    "trainer.create_subsampled_datasets(\n",
    "    dataset='stead',\n",
    "    output_dir='preprocessed_data/stead_splits',\n",
    "    noise_percentages=[], \n",
    "    subsampling_factor=1, \n",
    "    maintain_constant_size=False,\n",
    "    save_train_val_test_splits=True, \n",
    "    val_ratio=0.2, \n",
    "    test_ratio=0.3,\n",
    "    random_state_mode='pseudorandom',\n",
    "    base_random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c88046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Train batches: 2\n",
      "Val batches: 1\n",
      "Using HDF5Generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:47:50.525837: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:447] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2025-07-04 17:47:50.525877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Memory usage: 1835008 bytes free, 25402343424 bytes total.\n",
      "2025-07-04 17:47:50.526065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:461] Possibly insufficient driver version: 525.85.12\n",
      "2025-07-04 17:47:50.526081: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:1592 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer 'conv1d' (type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D] name: \n\nCall arguments received by layer 'conv1d' (type Conv1D):\n  • inputs=tf.Tensor(shape=(256, 3014, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RepresentationLearningMultipleAutoencoder()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_train.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_val.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_test.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_hdf5_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recovar/reproducibility/direct_trainer.py:426\u001b[0m, in \u001b[0;36mDirectTrainer.train\u001b[0;34m(self, model, dataset_path, train_dataset_path, val_dataset_path, test_dataset_path, epochs, batch_size, learning_rate, val_ratio, test_ratio, random_state, use_hdf5_generator)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_gen)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHDF5Generator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_hdf5_generator\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInMemoryDataGenerator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# Clean up temporary files if created\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_path \u001b[38;5;129;01mand\u001b[39;00m use_hdf5_generator:\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/recovar/representation_learning_models.py:272\u001b[0m, in \u001b[0;36mRepresentationLearningMultipleAutoencoder.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_noise(x)\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize2(x)\n\u001b[0;32m--> 272\u001b[0m f1, y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m f2, y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder2(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    274\u001b[0m f3, y3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder3(x, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/recovar/representation_learning_models.py:79\u001b[0m, in \u001b[0;36mAutoencoderBlock.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp(inputs)\n\u001b[1;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 79\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder(f, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f, y\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/recovar/representation_learning_models.py:50\u001b[0m, in \u001b[0;36mAutoencoderBlock._encoder\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_encoder\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training):\n\u001b[0;32m---> 50\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/RECOVAR_EGE/lib/python3.10/site-packages/recovar/layers.py:135\u001b[0m, in \u001b[0;36mDownsample.call\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    134\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding(x)\n\u001b[0;32m--> 135\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    137\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer 'conv1d' (type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D] name: \n\nCall arguments received by layer 'conv1d' (type Conv1D):\n  • inputs=tf.Tensor(shape=(256, 3014, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = RepresentationLearningMultipleAutoencoder()\n",
    "\n",
    "history = trainer.train(\n",
    "    model=model,\n",
    "    train_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_train.hdf5',\n",
    "    val_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_val.hdf5',\n",
    "    test_dataset_path='preprocessed_data/stead_splits/FULL_DATASET_SUBSAMPLED_0_test.hdf5',  # Optional\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    use_hdf5_generator=True  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RECOVAR_EGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
