{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 00:23:11.803248: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-27 00:23:11.840524: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-27 00:23:11.840560: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-27 00:23:11.840584: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-27 00:23:11.847316: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from recovar.config import BATCH_SIZE\n",
    "from recovar.representation_learning_models import (\n",
    "    RepresentationLearningSingleAutoencoder,\n",
    "    RepresentationLearningDenoisingSingleAutoencoder,\n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")\n",
    "from recovar.classifier_models import (\n",
    "    ClassifierAutocovariance, \n",
    "    ClassifierAugmentedAutoencoder, \n",
    "    ClassifierMultipleAutoencoder\n",
    ")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Configuration\n",
    "# ============================\n",
    "\n",
    "# Paths to your data\n",
    "TEST_DATA_PATH = 'data/X_test_1280sample.npy'  # Replace with your actual path\n",
    "TEST_LABEL_PATH = 'data/Y_test_1280sample.npy'  # Replace with your actual path\n",
    "\n",
    "# Paths to your model\n",
    "MODEL_PATH = 'models/representation_cross_covariances.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1280, 3000, 3)\n",
      "Test label shape: (1280,)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2. Data loading\n",
    "# ============================\n",
    "X_test = np.load(TEST_DATA_PATH)\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "Y_test = np.load(TEST_LABEL_PATH)  # Expected shape: (num_samples)\n",
    "print(f\"Test label shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 00:23:24.415472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2025-08-27 00:23:24.416514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 18488 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2025-08-27 00:23:24.417395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 18488 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:67:00.0, compute capability: 8.6\n",
      "2025-08-27 00:23:24.418288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 21775 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3. Representation Learning Model Instantiation\n",
    "# ============================\n",
    "\n",
    "# Choose the model you want to train\n",
    "# For example, using RepresentationLearningSingleAutoencoder\n",
    "#model = RepresentationLearningSingleAutoencoder(\n",
    "#    name=\"rep_learning_autoencoder\"\n",
    "#)\n",
    "\n",
    "# Alternatively, you can choose other models:\n",
    "# model = RepresentationLearningDenoisingSingleAutoencoder(\n",
    "#     name=\"rep_learning_denoising_autoencoder\",\n",
    "#     input_noise_std=1e-6,\n",
    "#     denoising_noise_std=2e-1\n",
    "# )\n",
    "model = RepresentationLearningMultipleAutoencoder(\n",
    "     name=\"rep_learning_autoencoder_ensemble\",\n",
    "     input_noise_std=1e-6,\n",
    "     eps=1e-27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 00:23:27.906793: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-08-27 00:23:37.995500: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 43.95MiB (rounded to 46080000)requested by op Square\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-08-27 00:23:37.995552: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-08-27 00:23:37.995573: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 8, Chunks in use: 8. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 40B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995585: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995598: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995609: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995619: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995632: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 15.0KiB allocated for chunks. 15.0KiB in use in bin. 15.0KiB client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995645: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 6, Chunks in use: 5. 97.5KiB allocated for chunks. 80.0KiB in use in bin. 80.0KiB client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995655: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995665: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995675: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995684: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995694: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995704: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995714: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995724: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995734: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995744: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995758: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 43.95MiB allocated for chunks. 43.95MiB in use in bin. 43.95MiB client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995772: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 86.75MiB allocated for chunks. 86.75MiB in use in bin. 43.95MiB client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995790: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995800: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-08-27 00:23:37.995812: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 43.95MiB was 32.00MiB, Chunk State: \n",
      "2025-08-27 00:23:37.995821: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 137166848\n",
      "2025-08-27 00:23:37.995832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000000 of size 256 next 1\n",
      "2025-08-27 00:23:37.995841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000100 of size 1280 next 2\n",
      "2025-08-27 00:23:37.995850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000600 of size 256 next 3\n",
      "2025-08-27 00:23:37.995859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000700 of size 256 next 4\n",
      "2025-08-27 00:23:37.995874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000800 of size 256 next 5\n",
      "2025-08-27 00:23:37.995887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000900 of size 256 next 6\n",
      "2025-08-27 00:23:37.995900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000a00 of size 256 next 7\n",
      "2025-08-27 00:23:37.995909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de2000b00 of size 46080000 next 8\n",
      "2025-08-27 00:23:37.995920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4bf2b00 of size 256 next 9\n",
      "2025-08-27 00:23:37.995928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4bf2c00 of size 256 next 10\n",
      "2025-08-27 00:23:37.995937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4bf2d00 of size 15360 next 13\n",
      "2025-08-27 00:23:37.995945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f0de4bf6900 of size 17920 next 14\n",
      "2025-08-27 00:23:37.995953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4bfaf00 of size 16384 next 15\n",
      "2025-08-27 00:23:37.995961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4bfef00 of size 16384 next 16\n",
      "2025-08-27 00:23:37.995969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4c02f00 of size 16384 next 17\n",
      "2025-08-27 00:23:37.995977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4c06f00 of size 16384 next 18\n",
      "2025-08-27 00:23:37.995989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4c0af00 of size 16384 next 19\n",
      "2025-08-27 00:23:37.996003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f0de4c0ef00 of size 90968320 next 18446744073709551615\n",
      "2025-08-27 00:23:37.996016: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-08-27 00:23:37.996033: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 256 totalling 2.0KiB\n",
      "2025-08-27 00:23:37.996047: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-08-27 00:23:37.996059: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2025-08-27 00:23:37.996076: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 16384 totalling 80.0KiB\n",
      "2025-08-27 00:23:37.996094: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 46080000 totalling 43.95MiB\n",
      "2025-08-27 00:23:37.996110: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 90968320 totalling 86.75MiB\n",
      "2025-08-27 00:23:37.996121: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 130.79MiB\n",
      "2025-08-27 00:23:37.996130: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 137166848 memory_limit_: 137166848 available bytes: 0 curr_region_allocation_bytes_: 274333696\n",
      "2025-08-27 00:23:37.996148: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       137166848\n",
      "InUse:                       137148928\n",
      "MaxInUse:                    137148928\n",
      "NumAllocs:                          37\n",
      "MaxAllocSize:                 90968320\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-08-27 00:23:37.996161: W tensorflow/tsl/framework/bfc_allocator.cc:497] ********************************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2025-08-27 00:23:37.996186: W tensorflow/core/framework/op_kernel.cc:1827] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'normalize_1' (type NormalizeStd).\n\n{{function_node __wrapped__Square_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Square] name: \n\nCall arguments received by layer 'normalize_1' (type NormalizeStd):\n  • x=tf.Tensor(shape=(1280, 3000, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 4. Model Compilation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(MODEL_PATH)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/onur_tfgpu2_14/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Code/recovar/recovar/representation_learning_models.py:268\u001b[0m, in \u001b[0;36mRepresentationLearningMultipleAutoencoder.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    265\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp(inputs)\n\u001b[1;32m    266\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 268\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_noise(x)\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize2(x)\n",
      "File \u001b[0;32m~/Code/recovar/recovar/layers.py:23\u001b[0m, in \u001b[0;36mNormalizeStd.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     std \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps \u001b[38;5;241m+\u001b[39m std)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'normalize_1' (type NormalizeStd).\n\n{{function_node __wrapped__Square_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Square] name: \n\nCall arguments received by layer 'normalize_1' (type NormalizeStd):\n  • x=tf.Tensor(shape=(1280, 3000, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 4. Model Compilation\n",
    "# ============================\n",
    "model.compile()\n",
    "model(X_test)\n",
    "model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note: One should be careful about the compatibility of the classifier wrappers with the models. RepresentationLearningSingleAutoencoder and RepresentationLearningDenoising\\nAutoencoder are compatible with ClassifierAutocovariance, ClassifierAugmentedAutoencoder. However, RepresentationLearningMultipleAutoencoder is only compatible with \\nClassifierMultipleAutoencoder. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# 5. Classifier Model Instantiation\n",
    "# ============================\n",
    "\n",
    "# Choose the model for classification. This is just for convenience, these models are actually wrappers around\n",
    "#representation learning models.\n",
    "# For example, using RepresentationLearningSingleAutoencoder\n",
    "# model_classifier = ClassifierAutocovariance(model)\n",
    "\n",
    "# Alternatively, you can choose other wrappers. \n",
    "# model_classifier = ClassifierAugmentedAutoencoder(model)\n",
    "model_classifier = ClassifierMultipleAutoencoder(model)\n",
    "\n",
    "\"\"\"Note: One should be careful about the compatibility of the classifier wrappers with the models. RepresentationLearningSingleAutoencoder and RepresentationLearningDenoising\n",
    "Autoencoder are compatible with ClassifierAutocovariance, ClassifierAugmentedAutoencoder. However, RepresentationLearningMultipleAutoencoder is only compatible with \n",
    "ClassifierMultipleAutoencoder. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 6. Obtain earthquake probabilities\n",
    "# ============================\n",
    "earthquake_scores = model_classifier(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ============================\n",
    "# 7. Plot ROC curve.\n",
    "# ============================\n",
    "fpr, tpr, __ = roc_curve(Y_test, earthquake_scores)\n",
    "auc_score = roc_auc_score(y_true=Y_test, y_score=earthquake_scores)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onur_tfgpu2_14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
